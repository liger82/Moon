---
layout: post
title: "RL: Introduction"
date: 2020-10-12
excerpt: ""
categories: [RL/RL]
tags : [Reinforcement Learning, RL, Sutton]
comments: true
---

Sutton 교수의 "introduction to reinforcement learning" 교재를 기반으로 공부한 것을 정리하도록 하겠습니다.

---

### 강화학습이란?
* 상호작용으로부터 배우는 목표지향적 학습
* 학습 과정에서 컴퓨터를 활용하는 방법
* 이상적인 학습 환경을 가정하고 그 안에서 다양한 학습 방법이 갖는 효과를 분석


즉, 주어진 상황에서 어떠한 행동을 취할지를 학습하는 것이다.  
그 행동의 결과는 최대한의 보상을 가져다 주어야 하며 그 보상함수는 수치적으로 표현될 수 있어야 한다.  
Agent는 어떠한 지침(지도)도 받지 않고 시행착오를 통해 최대의 보상을 가져다주는 행동을 찾아내야만 한다.  
또한 직접적인 행동의 결과 뿐만 아니라 그 다음 상황에도 영향을 받는 지연된 보상도 고려해야 한다.

### 강화학습이 지도/비지도 학습과 구별되는 점은 다음과 같다.
* 지침이 아닌 상호작용으로부터 학습(지도 X)
* 데이터 집합 내 숨겨진 구조를 찾지 않음(비지도 X)
* 탐험(exploration)과 활용(exploitation)의 절충이다
    * 활용: 많은 보상을 얻기 위해 과거에 보상을 얻는 데 효과적이었던 행동들을 선호
    * 탐험: 효과적인 행동을 발견하기 위해 과거에 하지 않았던 행동들을 시도
    
### 강화학습의 구성요소
학습자(agent), 주변 환경, 정책(policy), 보상신호(reward signal), 가치 함수(value function), 주변 환경에 대한 모델(필수 X)

- 정책: agent가 인지한 주변 환경의 상태에 대해 학습자가 취해야 할 행동을 결정
- 보상 신호: 강화학습이 성취해야 할 목표를 정의. agent는 보상신호의 크기로부터 그 행동이 좋은 것인지 나쁜 것인지 판단할 수 있다
- 가치함수: 장기적인 관점에서 무엇이 좋은 것인가를 알려준다. 특정 상태의 "가치"는 그 상태의 시작점으로부터 일정시간 동안 학습자가 기대할 수 있는 보상의 총량이다.
보상이 어떤 순간에 주변 환경의 상태에 내재된 고유의 desirability 라면, 가치는 특정 시점 이후의 상태와 그 상태에 포함된 장점을 고려하여 장기적 관점에서 평가한 장점이다.
행동은 보상보다는 가치에 초점을 두어 결정된다. (ex 특정상태에서의 행동이 보상이 적더라도 그 이후에 가치가 높아지는 행동이면 그 행동을 택한다.) 
다만, 보상은 주변 환경으로부터 주어지지만 가치는 학습자의 생애주기 동안 반복적으로 추정되어야 한다
- 환경 모델 : 환경이 어떻게 변화할지 추정할 수 있게 해준다. 환경 모델은 현재 상태와 그에 따라 취해지는 행동으로부터 다음 상태와 보상을 예측한다.
모델은 계획을 위해서 사용된다. 계획은 미래의 상황을 경험하기 전에 가능성만을 고려하여 일련의 행동을 결정하는 방법이다.
    * model-based 방법: 모델과 계획을 사용하여 문려해결
    * model-free 방법: 전적으로 시행착인만을 사용하여 문제해결
* 시행착오로부터 환경 모델을 학습하고 동시에 그 모델을 사용하여 계획하는 과정을 수행하는 RL 방법도 있음 (8장에서 다룸)
  
