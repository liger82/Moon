---
layout: post
title: "[Paper Review] Tacotron2 : NATURAL TTS SYNTHESIS BY CONDITIONING WAVENET ON MEL SPECTROGRAM PREDICTIONS"
date: 2021-11-01
excerpt: "Tacotron2"
categories: [NLP/Architecture]
tags : [tacotron2, speech synthesis, wavenet,text-to-speech, tts]
comments: true
---

* paper : [paper link](https://arxiv.org/pdf/1712.05884v2.pdf){:target="_blank"}
* github : [github link](){:target="_blank"}

<br>

> <subtitle> Abstract </subtitle>

이 논문은 텍스트로부터 바로 음성 합성을 하는 뉴럴넷 아키텍쳐인 Tacotron2 에 대해 다룬다. 이 시스템은 recurrent seq2seq feature prediction network로 구성되어 있다. 이는 문자 임베딩을 mel-scale spectrograms 으로 매핑한다. spectrogram 으로부터 시간 기준 파형을 합성하기 위해, 변형된 버전의 WaveNet model을 vocoder로 사용한다. tacotron2는 4.53의 MOS(mean opinion score)를 달성했다.(전문 기록 발화 수준인 MOS 4.58 과 유사한 수준). 설계를 검증하기 위해 이 시스템의 주요 구성요소를 대상으로 ablation study 를 진행했고, WaveNet의 조건적 입력으로 mel spectrograms 을 사용하는 것의 영향력을 평가했다. 또한 이런 표현 방식이 WaveNet 아키텍쳐의 사이즈를 크게 줄일 수 있다는 것도 보였다.

<br>

> <subtitle> 1. Introduction </subtitle>

TTS 는 여러 투자와 시도에도 도전적인 영역으로 남아있다. 앞서 시도된 것들은 다음과 같다.

1. Concatenative synthesis
    - 사전에 녹음된 작은 단위 파형을 잇는 방식으로 합성
    - 오랜 기간 SOTA
2. Statistical parametric speech synthesis
    - vocoder 를 사용하여 speech feature 의 부드러운 궤적(경로)을 직접적으로 생성하는 방식으로 음성 합성
    - concatenative synthesis 의 단점이 단위마다 잇는 경계에서의 부자연스러움을 꽤 해결
    - 그러나, 인간의 음성과 비교하면 종종 얼버무리고 부자연스러운 부분이 나옴.
3. WaveNet
    - time domain 파형을 생성하는 모델
    - 실제 인간의 음성과 유사한 품질의 음성을 만들어냄
    - 문제는 입력 데이터가 복잡
        - linguistic features, predicted log fundamental frequency (F0), and phoneme durations
4. Tacotron
    - 문자 시퀀스로부터 magnitude spectrograms를 생성하는 seq2seq 아키텍쳐
    - 언어적, 음향적 특징들을 생산하는 것 대신에 단일한 뉴럴넷을 사용함으로써 전통적인 음성 합성 파이프라인을 간편화함. 
    - magnitude spectrograms 를 vocode(voice encode)하기 위해 tacotron 은 Griffin-Lim algorithm 으로 phase 를 추정하고 inverse short-time Fourier transform 을 한다.
5. Deep Voice 3
    - tacotron2 와 비슷한 접근 방식이지만, 음성의 자연스러움이 인간의 음성과 필적할만하지는 않다.
6. Char2Wav
    - neural vocoder 를 활용한 end-to-end TTS 를 구현한 다른 방식
    - 전통적인 vocoder features 를 사용하고 tacotron2 와는 전혀 다른 아키텍쳐를 지님

<br>

* Tacotron2 
    - 이전 접근 방법들의 장점들을 엮은 음성합성 방식
    - Attention 기반 seq2seq TTS 모델 구조
    - <문장, 음성> 쌍으로 이루어진 데이터만으로 별도의 작업 없이 학습이 가능한 **End-to-End 모델**
    - MOS(음성합성 품질 테스트)에서 높은 점수를 얻음.

<br>

> <subtitle> 2. Model Architecture </subtitle>

<br>

> <subtitle> 3. Experiments & Results </subtitle>


<br>

> <subtitle> 4. Conclusion </subtitle>


<br>


<br>

---

> <subtitle> References </subtitle>

* [https://joungheekim.github.io/2020/10/08/paper-review/](https://joungheekim.github.io/2020/10/08/paper-review/){:target="_blank"}


<br>
